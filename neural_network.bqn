âŸ¨DualâŸ© â† â€¢Import "dual.bqn"
âŸ¨GnuPlotâŸ© â† â€¢Import "BQN-Gnuplot/Gnuplot.bqn"
rng â† â€¢MakeRand 2

# Two layer neural network with weights and biases. Both layers are sigmoid activated
Network â† {lr ğ•Š inszâ€¿hidszâ€¿outsz:
    âŸ¨insz, outsz, lrâŸ© â‡

    real_l1_weights â† hidszâ€¿insz rng.Range 0
    real_l1_biases â† hidsz rng.Range 0

    real_l2_weights â† outszâ€¿hidsz rng.Range 0
    real_l2_biases â† outsz rng.Range 0

    n_params â‡ (hidszÃ—insz) + hidsz + (outszÃ—hidsz) + outsz

    z â‡ 0 Dual n_paramsâ¥Š0

    l1_weights â‡ (â†•â‰¢real_l1_weights) {hâ€¿i ğ•Š w:
        idx â† (h Ã— insz) + i
        eps â† 1âŒ¾(idxâŠ¸âŠ‘) n_paramsâ¥Š0
        w Dual eps
    }Â¨real_l1_weights

    l1_biases â‡ (â†•â‰¢real_l1_biases) {h ğ•Š w:
        idx â† (hidsz Ã— insz) + h
        eps â† 1âŒ¾(idxâŠ¸âŠ‘) n_paramsâ¥Š0
        w Dual eps
    }Â¨real_l1_biases

    l2_weights â‡ (â†•â‰¢real_l2_weights) {oâ€¿h ğ•Š w:
        idx â† (hidsz Ã— insz) + hidsz + (o Ã— hidsz) + h
        eps â† 1âŒ¾(idxâŠ¸âŠ‘) n_paramsâ¥Š0
        w Dual eps
    }Â¨real_l2_weights

    l2_biases â‡ (â†•â‰¢real_l2_biases) {o ğ•Š w:
        idx â† (hidsz Ã— insz) + hidsz + (outsz Ã— hidsz) + o
        eps â† 1âŒ¾(idxâŠ¸âŠ‘) n_paramsâ¥Š0
        w Dual eps
    }Â¨real_l2_biases


    Forward â‡ {
        x â† ğ•©
        # x â†© W1 * x
        x â†© {
            elementwise â† ğ•© {ğ•¨.Mul ğ•©}Â¨ x
            total â† z {ğ•¨.Add ğ•©}Â´ elementwise
            total
        }Ë˜l1_weights

        # x â†© x + b1
        x â†© l1_biases { ğ•¨.Add ğ•© }Â¨ x

        # x â†© sigmoid(x) = 1 Ã· (1 + exp(-x))
        x â†© { ((ğ•©.EExp@).Add 1).PowC Â¯1}Â¨ x

        # x â†© W2 * x
        x â†© {
            elementwise â† ğ•© {ğ•¨.Mul ğ•©}Â¨ x
            total â† z {ğ•¨.Add ğ•©}Â´ elementwise
            total
        }Ë˜l2_weights

        # x â†© x + b2
        x â†© l2_biases { ğ•¨.Add ğ•© }Â¨ x

        # x â†© sigmoid(x) = 1 Ã· (1 + exp(-x))
        x â†© { ((ğ•©.EExp@).Add 1).PowC Â¯1}Â¨ x
        x
    }

    Objective â‡ {real_y ğ•Š y_hat:
        se â† real_y {(ğ•©.Sub ğ•¨).PowC 2}Â¨ y_hat
        z {ğ•¨.Add ğ•©}Â´ net.z {ğ•¨.Add ğ•©}Â´Ë˜ se
    }
    Update â‡ {ğ•Š loss:
        l1_weights â†© (â†•â‰¢l1_weights) {hâ€¿i ğ•Š w:
            idx â† (h Ã— insz) + i
            w.Sub lr Ã— idx âŠ‘ loss.eps
        }Â¨l1_weights

        l1_biases â†© (â†•â‰¢l1_biases) {h ğ•Š w:
            idx â† (hidsz Ã— insz) + h
            w.Sub lr Ã— idx âŠ‘ loss.eps
        }Â¨l1_biases

        l2_weights â†© (â†•â‰¢l2_weights) {oâ€¿h ğ•Š w:
            idx â† (hidsz Ã— insz) + hidsz + (o Ã— hidsz) + h
            w.Sub lr Ã— idx âŠ‘ loss.eps
        }Â¨l2_weights

        l2_biases â†© (â†•â‰¢l2_biases) {o ğ•Š w:
            idx â† (hidsz Ã— insz) + hidsz + (outsz Ã— hidsz) + o
            w.Sub lr Ã— idx âŠ‘ loss.eps
        }Â¨l2_biases
    }
}

# # objective function:
# # f(x, y, z) = âŸ¨x > y, y < zâŸ©

# train_data â† âŸ¨
#     âŸ¨âŸ¨1, 2, 3âŸ©, âŸ¨0, 1âŸ©âŸ©,
#     âŸ¨âŸ¨5, Â¯1, 10âŸ©, âŸ¨1, 1âŸ©âŸ©,
#     âŸ¨âŸ¨2, 7, Â¯3âŸ©, âŸ¨0, 0âŸ©âŸ©,
#     âŸ¨âŸ¨20, 10, 0âŸ©, âŸ¨1, 0âŸ©âŸ©,
# âŸ©

# f(x, y, z) = âŸ¨x ^ y, y | zâŸ©

train_data â† âŸ¨
    âŸ¨âŸ¨0, 0, 0âŸ©, âŸ¨0, 0âŸ©âŸ©,
    âŸ¨âŸ¨0, 0, 1âŸ©, âŸ¨0, 1âŸ©âŸ©,
    âŸ¨âŸ¨0, 1, 0âŸ©, âŸ¨1, 1âŸ©âŸ©,
    âŸ¨âŸ¨0, 1, 1âŸ©, âŸ¨1, 1âŸ©âŸ©,
    âŸ¨âŸ¨1, 0, 0âŸ©, âŸ¨1, 0âŸ©âŸ©,
    âŸ¨âŸ¨1, 0, 1âŸ©, âŸ¨1, 1âŸ©âŸ©,
    âŸ¨âŸ¨1, 1, 0âŸ©, âŸ¨0, 1âŸ©âŸ©,
    âŸ¨âŸ¨1, 1, 1âŸ©, âŸ¨0, 1âŸ©âŸ©,
âŸ©
train_x â† > {F xâ€¿y: x}Â¨ train_data
train_y â† > {F xâ€¿y: y}Â¨ train_data

net â† 0.1 Network 3â€¿5â€¿2

loss_history â† â†•0

Show â† {ğ•¤
    â€¢Out "x ="
    â€¢Show train_x

    y_hat â† {net.Forward ğ•©}Ë˜ train_x

    â€¢Out "y_hat ="
    â€¢Show {ğ•©.n}Â¨ y_hat
    â€¢Out "y ="
    â€¢Show train_y

    loss â† train_y net.Objective y_hat

    â€¢Out "loss = " âˆ¾ â€¢Fmt loss.n
}

Step â† {ğ•Š loud:
    y_hat â† {net.Forward ğ•©}Ë˜ train_x

    loss â† train_y net.Objective y_hat

    net.Update loss

    loss_history â†© loss_history âˆ¾ âŸ¨loss.nâŸ©
}

Show 1
StepâŸ2000 0
Show 1

# plot loss history

plt â† GnuPlot âŸ¨
    "title 'Neural network training'"
    "xlabel 'Epochs'"
    "ylabel 'Loss'"
âŸ©

plt.Plot loss_historyâ€¿"with lines"
plt.Show @
